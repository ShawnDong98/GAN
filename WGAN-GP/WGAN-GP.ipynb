{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/ShawnDong98/GAN/blob/master/WGAN-GP/WGAN-GP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  torch\n",
    "from    torch import nn, optim, autograd\n",
    "import  numpy as np\n",
    "from    torch.nn import functional as F\n",
    "from    matplotlib import pyplot as plt\n",
    "import  random\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM = 128 # This overfits substantially; you're probably better off with 64\n",
    "BATCH_SIZE = 4 # Batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        preprocess = nn.Sequential(\n",
    "            nn.Linear(128, 4 * 4 * 4 * DIM),\n",
    "            #nn.BatchNorm2d(4 * 4 * 4 * DIM),  ## 他这里写错了\n",
    "            nn.BatchNorm1d(4 * 4 * 4 * DIM),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "\n",
    "        block1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(4 * DIM, 2 * DIM, 2, stride=2),\n",
    "            nn.BatchNorm2d(2 * DIM),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        block2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(2 * DIM, DIM, 2, stride=2),\n",
    "            nn.BatchNorm2d(DIM),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        deconv_out = nn.ConvTranspose2d(DIM, 3, 2, stride=2)\n",
    "\n",
    "        self.preprocess = preprocess\n",
    "        self.block1 = block1\n",
    "        self.block2 = block2\n",
    "        self.deconv_out = deconv_out\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.preprocess(input)\n",
    "        output = output.view(-1, 4 * DIM, 4, 4)\n",
    "        output = self.block1(output)\n",
    "        output = self.block2(output)\n",
    "        output = self.deconv_out(output)\n",
    "        output = self.tanh(output)\n",
    "        return output.view(-1, 3, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        main = nn.Sequential(\n",
    "            nn.Conv2d(3, DIM, 3, 2, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(DIM, 2 * DIM, 3, 2, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(2 * DIM, 4 * DIM, 3, 2, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "\n",
    "        self.main = main\n",
    "        self.linear = nn.Linear(4*4*4*DIM, 1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.main(input)\n",
    "        output = output.view(-1, 4*4*4*DIM)\n",
    "        output = self.linear(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = transforms.Compose([transforms.Resize(32),\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "                       ])\n",
    "\n",
    "dataset = datasets.ImageFolder(\n",
    "    root = \"../data/own_data/\", \n",
    "    transform=T,\n",
    ")\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True,\n",
    "    drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        # m.weight.data.normal_(0.0, 0.02)\n",
    "        nn.init.kaiming_normal_(m.weight)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成GP优化\n",
    "def gradient_penalty(D, xr, xf):\n",
    "    \"\"\"\n",
    "\n",
    "    :param D:\n",
    "    :param xr:\n",
    "    :param xf:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    LAMBDA = 10\n",
    "\n",
    "    # only constrait for Discriminator\n",
    "    xf = xf.detach()\n",
    "    xr = xr.detach()\n",
    "\n",
    "    # [b, 1] => [b, 2]\n",
    "    alpha = torch.rand(BATCH_SIZE, 1).cuda()\n",
    "    alpha = alpha.expand(BATCH_SIZE, int(xr.nelement()/BATCH_SIZE)).reshape(BATCH_SIZE, 3, 32, 32)\n",
    "\n",
    "    interpolates = alpha * xr + ((1 - alpha) * xf)\n",
    "    interpolates.requires_grad_()\n",
    "\n",
    "    disc_interpolates = D(interpolates)\n",
    "\n",
    "    gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n",
    "                              grad_outputs=torch.ones_like(disc_interpolates),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "\n",
    "    gp = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * LAMBDA\n",
    "\n",
    "    return gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# loader使用torchvision中自带的transforms函数\n",
    "loader = transforms.Compose([\n",
    "    transforms.ToTensor()])  \n",
    "\n",
    "unloader = transforms.ToPILImage()\n",
    "\n",
    "def imshow(tensor, title=None):\n",
    "    image = tensor.cpu().clone()  # we clone the tensor to not do changes on it\n",
    "    print(image.size())\n",
    "    image = image.squeeze(0)  # remove the fake batch dimension\n",
    "    print(image.size())\n",
    "    image = unloader(image)\n",
    "    plt.imshow(image)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    \n",
    "def toTensor(img):\n",
    "    assert type(img) == np.ndarray,'the img type is {}, but ndarry expected'.format(type(img))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = torch.from_numpy(img.transpose((2, 0, 1)))\n",
    "    return img.float().div(255).unsqueeze(0) \n",
    "    \n",
    "def tensor_to_np(tensor):\n",
    "    img = tensor.mul(255).byte()\n",
    "    img = img.cpu().squeeze(0).numpy().transpose((1, 2, 0))\n",
    "    return img\n",
    "    \n",
    "def show_from_tensor(tensor, title=None):\n",
    "    img = tensor.clone()\n",
    "    img = tensor_to_np(img)\n",
    "    plt.figure()\n",
    "    plt.imshow(img)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
