{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Function\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_linear(linear):\n",
    "    init.xavier_normal(linear.weight)\n",
    "    linear.bias.data.zero_()\n",
    "\n",
    "\n",
    "def init_conv(conv, glu=True):\n",
    "    init.kaiming_normal(conv.weight)\n",
    "    if conv.bias is not None:\n",
    "        conv.bias.data.zero_()\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EqualLR:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def compute_weight(self, module):\n",
    "        weight = getattr(module, self.name + '_orig')\n",
    "        fan_in = weight.data.size(1) * weight.data[0][0].numel()\n",
    "\n",
    "        return weight * sqrt(2 / fan_in)\n",
    "\n",
    "    # 这里的module是conv/linear\n",
    "    @staticmethod\n",
    "    def apply(module, name):\n",
    "        # 这一步仅仅执行了__init__以及实例化了一个对象\n",
    "        fn = EqualLR(name)\n",
    "\n",
    "        weight = getattr(module, name)\n",
    "        # 这里把module(也就是conv/linear)的weight参数删掉了\n",
    "        del module._parameters[name]\n",
    "        # 这里把原来的权重注册进去，新的权重没有注册吗？\n",
    "        # 新的权重在调用fn的时候注册， 也就是调用__call__的时候\n",
    "        module.register_parameter(name + '_orig', nn.Parameter(weight.data))\n",
    "        \n",
    "        module.register_forward_pre_hook(fn)\n",
    "\n",
    "        # module和fn到底是什么关系？\n",
    "        return fn\n",
    "\n",
    "    # 这里的module是fn\n",
    "    def __call__(self, module, input):\n",
    "        weight = self.compute_weight(module)\n",
    "        setattr(module, self.name, weight)\n",
    "\n",
    "def equal_lr(module, name='weight'):\n",
    "    EqualLR.apply(module, name)\n",
    "\n",
    "    return module\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FusedUpsample(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, kernel_size, padding=0):\n",
    "        super().__init__()\n",
    "\n",
    "        weight = torch.randn(in_channel, out_channel, kernel_size, kernel_size)\n",
    "        bias = torch.zeros(out_channel)\n",
    "\n",
    "        fan_in = in_channel * kernel_size * kernel_size\n",
    "        self.multiplier = sqrt(2 / fan_in)\n",
    "\n",
    "        self.weight = nn.Parameter(weight)\n",
    "        self.bias = nn.Parameter(bias)\n",
    "\n",
    "        self.pad = padding\n",
    "\n",
    "    def forward(self, input):\n",
    "        # relu的kaiming_normal\n",
    "        weight = F.pad(self.weight * self.multiplier, [1, 1, 1, 1])\n",
    "        weight = (\n",
    "            weight[:, :, 1:, 1:]\n",
    "            + weight[:, :, :-1, 1:]\n",
    "            + weight[:, :, 1:, :-1]\n",
    "            + weight[:, :, :-1, :-1]\n",
    "        ) / 4\n",
    "\n",
    "        out = F.conv_transpose2d(input, weight, self.bias, stride=2, padding=self.pad)\n",
    "\n",
    "        return out\n",
    "\n",
    "class FusedDownsample(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, kernel_size, padding=0):\n",
    "        super().__init__()\n",
    "\n",
    "        weight = torch.randn(out_channel, in_channel, kernel_size, kernal_size)\n",
    "        bias = torch.zeros(out_channel)\n",
    "\n",
    "        fan_in = in_channel * kernel_size * kernel_size\n",
    "        self.multiplier = sqrt(2 / fan_in)\n",
    "\n",
    "        self.weight = nn.Parameter(weight)\n",
    "        self.bias = nn.Parameter(bias)\n",
    "\n",
    "        self.pad = padding\n",
    "\n",
    "    def forward(self, input):\n",
    "        weight = F.pad(self.weight * self.multiplier, [1, 1, 1, 1])\n",
    "        weight = (\n",
    "            weight[:, :, 1:, 1:]\n",
    "            + weight[:, :, :-1, 1:]\n",
    "            + weight[:, :, 1:, :-1]\n",
    "            + weight[:, :, :-1, :-1]\n",
    "        ) / 4\n",
    "\n",
    "        out = F.conv2d(input, weight, self.bias, stride=2, padding=self.pad)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PixelNorm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return input / torch.sqrt(torch.mean(input ** 2, dim=1, keepdim=True) + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlurFunctionBackward(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, grad_output, kernel, kernel_flip):\n",
    "        ctx.save_for_backward(kernel, kernel_flip)\n",
    "\n",
    "        grad_input = F.conv2d(grad_output, kernel_flip, padding=1, groups=grad_output.shape[1])\n",
    "\n",
    "        return grad_input\n",
    "\n",
    "\n",
    "    # 求二次梯度，用于梯度惩罚\n",
    "    @staticmethod\n",
    "    def backward(ctx, gradgrad_output):\n",
    "        kernel, kernel_flip = ctx.saved_tensors\n",
    "\n",
    "        grad_input = F.conv2d(gradgrad_output, kernel, padding=1, groups=gradgrad_output.shape[1])\n",
    "\n",
    "        return grad_input, None, None\n",
    "\n",
    "class BlurFuction(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, kernel, kernel_flip):\n",
    "        ctx.save_for_backward(kernel, kernel_flip)\n",
    "\n",
    "        output = F.conv2d(input, kernel, padding=1, groups=input.shape[1])\n",
    "\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        kernel, kernel_flip = ctx.saved_tensors\n",
    "\n",
    "        grad_input = BlurFunctionBackward.apply(grad_output, kernel, kernel_flip)\n",
    "\n",
    "        return grad_input, None, None\n",
    "\n",
    "\n",
    "blur = BlurFuction.apply\n",
    "\n",
    "class Blur(nn.Module):\n",
    "    def __init__(self, channel):\n",
    "        super().__init__()\n",
    "\n",
    "        weight = torch.tensor([[1, 2, 1], [2, 4 ,2], [1, 2, 1]], dtype=torch.float32)\n",
    "        weight = weight.view(1, 1, 3, 3)\n",
    "        weight = weight / weight.sum()\n",
    "        # 对最后两维进行行和列的翻转\n",
    "        weight_flip = torch.flip(weight, [2, 3])\n",
    "\n",
    "        # 根据通道数，复制多个卷积核\n",
    "        self.register_buffer('weight', weight.repeat(channel, 1, 1, 1))\n",
    "        self.register_buffer('weight_flip', weight_flip.repeat(channel, 1, 1, 1))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return blur(input, self.weight, self.weight_flip)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EqualConv2d(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        conv = nn.Conv2d(*args, **kwargs)\n",
    "        conv.weight.data.normal_()\n",
    "        conv.bias.data.zero_()\n",
    "        self.conv = equal_lr(conv)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.conv(input)\n",
    "\n",
    "\n",
    "class EqualLinear(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        linear = nn.Linear(in_dim, out_dim)\n",
    "        linear.weight.data.normal_()\n",
    "        linear.bias.data.zero_()\n",
    "\n",
    "        self.linear = equal_lr(linear)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.linear(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, kernel_size, padding, kernel_size2=None, padding2=None, downsample=False, fused=False):\n",
    "        super().__init__()\n",
    "\n",
    "        pad1 = padding\n",
    "        pad2 = padding\n",
    "        if padding2 is not None:\n",
    "            pad2 = padding2\n",
    "\n",
    "        kernel1 = kernel_size\n",
    "        kernel2 = kernel_size\n",
    "        if kernel_size2 is not None:\n",
    "            kernel2 = kernel_size2\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            EqualConv2d(in_channel, out_channel, kernel1, padding=pad1),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "\n",
    "        if downsample:\n",
    "            if fused:\n",
    "                self.conv2 = nn.Sequential(\n",
    "                    Blur(out_channel),\n",
    "                    # 为什么混淆降采样步长为2\n",
    "                    FusedDownsample(out_channel, out_channel, kernel2, padding=pad2),\n",
    "                    nn.LeakyReLU(0.2)\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                self.conv2 = nn.Sequential(\n",
    "                    Blur(out_channel),\n",
    "                    # 而卷积步长为1且池化？\n",
    "                    EqualConv2d(out_channel, out_channel, kernel2, padding=pad2),\n",
    "                    nn.AvgPool2d(2),\n",
    "                    nn.LeakyReLU(0.2)\n",
    "                )\n",
    "        else:\n",
    "            self.conv2 = nn.Sequential(\n",
    "                EqualConv2d(out_channel, out_channel, kernel2, padding=pad2),\n",
    "                nn.LeakyReLU(0.2)\n",
    "            )\n",
    "        \n",
    "\n",
    "    def forward(self, input):\n",
    "        out = self.conv1(input)\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class AdaptiveInstanceNorm(nn.Module):\n",
    "    def __init__(self, in_channel, style_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.norm = nn.InstanceNorm2d(in_channel)\n",
    "        self.style = EqualLinear(style_dim, in_channel * 2)\n",
    "\n",
    "        self.style.linear.bias.data[:in_channel] = 1\n",
    "        self.style.linear.bias.data[in_channel:] = 0\n",
    "\n",
    "    def forward(self, input, style):\n",
    "        # 添加第三维和第四维，用于广播\n",
    "        style = self.style(style).unsqueeze(2).unsqueeze(3)\n",
    "        # 将第一维分成两个tensor， \n",
    "        gamma, beta = style.chunk(2, 1)\n",
    "\n",
    "        out = self.norm(input)\n",
    "        out = gamma * out + beta\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class NoiseInjection(nn.Module):\n",
    "    def __init__(self, channel):\n",
    "        super().__init__()\n",
    "\n",
    "        self.weight = nn.Parameter(torch.zeros(1, channel, 1, 1))\n",
    "\n",
    "    def forward(self, image, noise):\n",
    "        return image + self.weight * noise\n",
    "\n",
    "\n",
    "\n",
    "class ConstantInput(nn.Module):\n",
    "    def __init__(self, channel, size=4):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input = nn.Parameter(torch.randn(1, channel, size, size))\n",
    "\n",
    "    \n",
    "    def forward(self, input):\n",
    "        batch = input.shape[0]\n",
    "        out = self.input.repeat(batch, 1, 1, 1)\n",
    "\n",
    "        return out\n",
    "    \n",
    "\n",
    "class StyleConvBlock(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, kernel_size=3, padding=1, style_dim=512, initial=False, upsample=False, fused=False):\n",
    "        super().__init__()\n",
    "\n",
    "        if initial:\n",
    "            self.conv1 = ConstantInput(in_channel)\n",
    "\n",
    "        else:\n",
    "            if upsample:\n",
    "                if fused:\n",
    "                    self.conv1 = nn.Sequential(\n",
    "                        FusedUpsample(\n",
    "                            in_channel, out_channel, kernel_size, padding=padding),\n",
    "                            Blur(out_channel)\n",
    "                    )\n",
    "\n",
    "                else:\n",
    "                    self.conv1 = nn.Sequential(\n",
    "                        nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "                        EqualConv2d(\n",
    "                            in_channel, out_channel, kernel_size, padding=padding\n",
    "                        ),\n",
    "                        Blur(out_channel)\n",
    "                    )\n",
    "\n",
    "            else:\n",
    "                self.conv1 = EqualConv2d(\n",
    "                    in_channel, out_channel, kernel_size, padding=padding\n",
    "                )\n",
    "        \n",
    "        self.noise1 = equal_lr(NoiseInjection(out_channel))\n",
    "        self.adain1 = AdaptiveInstanceNorm(out_channel, style_dim)\n",
    "        self.lrelu1 = nn.LeakyReLU(0.2)\n",
    "\n",
    "        self.conv2 = EqualConv2d(out_channel, out_channel, kernel_size, padding=padding)\n",
    "        self.noise2 = equal_lr(NoiseInjection(out_channel))\n",
    "        self.adain2 = AdaptiveInstanceNorm(out_channel, style_dim)\n",
    "        self.lrelu2 = nn.LeakyReLU(0.2)\n",
    "\n",
    "    def forward(self, input, style, noise):\n",
    "        out = self.conv1(input)\n",
    "        out = self.noise1(out, noise)\n",
    "        out = self.lrelu1(out)\n",
    "        out = self.adain1(out, style)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.noise2(out, noise)\n",
    "        out = self.lrelu2(out)\n",
    "        out = self.adain2(out, style)\n",
    "\n",
    "        return out\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里的生成器利用风格升采样产生图像\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, code_dim, fused=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.progression = nn.ModuleList(\n",
    "            [\n",
    "                StyleConvBlock(512, 512, 3, 1, initial=True), # 4\n",
    "                StyleConvBlock(512, 512, 3, 1, upsample=True), #8\n",
    "                StyleConvBlock(512, 512, 3, 1, upsample=True), # 16\n",
    "                StyleConvBlock(512, 512, 3, 1, upsample=True), # 32\n",
    "                StyleConvBlock(512, 256, 3, 1, upsample=True), #64\n",
    "                StyleConvBlock(256, 128, 3 ,1, upsample=True, fused=fused), #128\n",
    "                StyleConvBlock(128, 64, 3, 1, upsample=True, fused=fused), #256\n",
    "                StyleConvBlock(64, 32, 3, 1, upsample=True, fused=fused), #512\n",
    "                StyleConvBlock(32, 16, 3, 1, upsample=True, fused=fused), #1024\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.to_rgb = nn.ModuleList(\n",
    "            [\n",
    "                EqualConv2d(512, 3, 1),\n",
    "                EqualConv2d(512, 3, 1),\n",
    "                EqualConv2d(512, 3, 1),\n",
    "                EqualConv2d(512, 3, 1),\n",
    "                EqualConv2d(256, 3, 1),\n",
    "                EqualConv2d(128, 3, 1),\n",
    "                EqualConv2d(64, 3, 1),\n",
    "                EqualConv2d(32, 3, 1),\n",
    "                EqualConv2d(16, 3, 1)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(self, style, noise, step=0, alpha=-1, mixing_range=(-1, -1)):\n",
    "        out = noise[0]\n",
    "\n",
    "        if len(style) < 2:\n",
    "            # inject_index是用来干什么的？\n",
    "            # inject_index: 10\n",
    "            inject_index = [len(self.progression) + 1]\n",
    "\n",
    "        else:\n",
    "            # style = 2\n",
    "            # 从[0, step)选出不重复的len(style)-1个\n",
    "            inject_index = random.sample(list(range(step)), len(style) - 1)\n",
    "\n",
    "        # crossover又是做什么用的？\n",
    "        # \n",
    "        crossover = 0\n",
    "\n",
    "        for i, (conv, to_rgb) in enumerate(zip(self.progression, self.to_rgb)):\n",
    "            if mixing_range == (-1, -1):\n",
    "                # inject_index[crossover]\n",
    "                if crossover < len(inject_index) and i > inject_index[crossover]:\n",
    "                    crossover = min(crossover + 1, len(style))\n",
    "\n",
    "                style_step = style[crossover]\n",
    "            \n",
    "            else:\n",
    "                # mixing_range[0]: 0\n",
    "                # mixing_range[1]: 1\n",
    "                # 当i为0和1时使用source的style\n",
    "                # 其它时候使用target的style\n",
    "                if mixing_range[0] <= i <= mixing_range[1]:\n",
    "                    style_step = style[1]\n",
    "\n",
    "                else:\n",
    "                    style_step = style[0]\n",
    "                    \n",
    "            if i > 0 and step > 0:\n",
    "                out_prev = out\n",
    "\n",
    "            out = conv(out, style_step, noise[i])\n",
    "\n",
    "            # step用于控制到网络哪一层停止\n",
    "            if i == step:\n",
    "                # 通道64->3\n",
    "                out = to_rgb(out)\n",
    "\n",
    "                if i > 0 and 0 <= alpha < 1:\n",
    "                    # 上一层的输出上采样后和这层融合\n",
    "                    # 用于网络新层和旧层间的过度\n",
    "                    skip_rgb = self.to_rgb[i-1](out_prev)\n",
    "                    skip_rgb = F.interpolate(skip_rgb, scale_factor=2, mode='nearest')\n",
    "                    out = (1 - alpha) * skip_rgb + alpha * out\n",
    "\n",
    "                break\n",
    "        return out\n",
    "\n",
    "\n",
    "# Style生成器主要用线性层用于生成风格W\n",
    "class StyledGenerator(nn.Module):\n",
    "    def __init__(self, code_dim=512, n_mlp=8):\n",
    "        super().__init__()\n",
    "\n",
    "        self.generator = Generator(code_dim)\n",
    "\n",
    "        layers = [PixelNorm()]\n",
    "\n",
    "        for i in range(n_mlp):\n",
    "            layers.append(EqualLinear(code_dim, code_dim))\n",
    "            layers.append(nn.LeakyReLU(0.2))\n",
    "\n",
    "        self.style = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, input, noise=None, step=0, alpha=-1, mean_style=None, style_weight=0, mixing_range=(-1, -1)):\n",
    "        styles = []\n",
    "        if type(input) not in (list, tuple):\n",
    "            input = [input]\n",
    "\n",
    "        for i in input:\n",
    "            styles.append(self.style(i))\n",
    "\n",
    "        batch = input[0].shape[0]\n",
    "\n",
    "        if noise is None:\n",
    "            noise = []\n",
    "\n",
    "            for i in range(step + 1):\n",
    "                size = 4 * 2 ** i\n",
    "                noise.append(torch.randn(batch, 1, size, size, device=input[0].device))\n",
    "\n",
    "        if mean_style is not None:\n",
    "            styles_norm = []\n",
    "\n",
    "            for style in styles:\n",
    "                styles_norm.append(mean_style + style_weight * (style - mean_style))\n",
    "\n",
    "            styles = styles_norm\n",
    "\n",
    "        return self.generator(styles, noise, step, alpha, mixing_range=mixing_range)\n",
    "\n",
    "    def mean_style(self, input):\n",
    "        style = self.style(input).mean(0, keepdim=True)\n",
    "\n",
    "        return style\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, fused=True, from_rgb_activate=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.progression = nn.ModuleList(\n",
    "            [\n",
    "                ConvBlock(16, 32, 3, 1, downsample=True, fused=fused),  # 512\n",
    "                ConvBlock(32, 64, 3, 1, downsample=True, fused=fused),  # 256\n",
    "                ConvBlock(64, 128, 3, 1, downsample=True, fused=fused),  # 128\n",
    "                ConvBlock(128, 256, 3, 1, downsample=True, fused=fused),  # 64\n",
    "                ConvBlock(256, 512, 3, 1, downsample=True),  # 32\n",
    "                ConvBlock(512, 512, 3, 1, downsample=True),  # 16\n",
    "                ConvBlock(512, 512, 3, 1, downsample=True),  # 8\n",
    "                ConvBlock(512, 512, 3, 1, downsample=True),  # 4\n",
    "                ConvBlock(513, 512, 3, 1, 4, 0),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        def make_from_rgb(out_channel):\n",
    "            if from_rgb_activate:\n",
    "                return nn.Sequential(EqualConv2d(3, out_channel, 1), nn.LeakyReLU(0.2))\n",
    "\n",
    "            else:\n",
    "                return EqualConv2d(3, out_channel, 1)\n",
    "\n",
    "        self.from_rgb = nn.ModuleList(\n",
    "            [\n",
    "                make_from_rgb(16),\n",
    "                make_from_rgb(32),\n",
    "                make_from_rgb(64),\n",
    "                make_from_rgb(128),\n",
    "                make_from_rgb(256),\n",
    "                make_from_rgb(512),\n",
    "                make_from_rgb(512),\n",
    "                make_from_rgb(512),\n",
    "                make_from_rgb(512),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "\n",
    "        self.n_layer = len(self.progression)\n",
    "\n",
    "        self.linear = EqualLinear(512, 1)\n",
    "\n",
    "    def forward(self, input, step=0, alpha=-1):\n",
    "        # step, step-1, ..., 0\n",
    "        for i in range(step, -1, -1):\n",
    "            # index用于控制使用倒数哪几层\n",
    "            index = self.n_layer - i - 1\n",
    "\n",
    "            if i == step:\n",
    "                out = self.from_rgb[index](input)\n",
    "\n",
    "            if i == 0:\n",
    "                out_std = torch.sqrt(out.var(0, unbiased=False) + 1e-8)\n",
    "                mean_std = out_std.mean()\n",
    "                mean_std = mean_std.expand(out.size(0), 1, 4, 4)\n",
    "                out = torch.cat([out, mean_std], 1)\n",
    "\n",
    "            out = self.progression[index](out)\n",
    "\n",
    "            if i > 0:\n",
    "                if i == step and 0 <= alpha < 1:\n",
    "                    skip_rgb = F.avg_pool2d(input, 2)\n",
    "                    skip_rgb = self.from_rgb[index + 1](skip_rgb)\n",
    "\n",
    "                    out = (1 - alpha) * skip_rgb + alpha * out\n",
    "\n",
    "        out = out.squeeze(2).squeeze(2)\n",
    "\n",
    "        out = self.linear(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from torchvision import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_mean_style(generator, device):\n",
    "    mean_style = None\n",
    "\n",
    "    for i in range(10):\n",
    "        style = generator.mean_style(torch.randn(1024, 512).to(device))\n",
    "\n",
    "        if mean_style is None:\n",
    "            mean_style = style\n",
    "\n",
    "        else:\n",
    "            mean_style += style\n",
    "\n",
    "    mean_style /= 10\n",
    "    return mean_style\n",
    "\n",
    "@torch.no_grad()\n",
    "def sample(generator, step, mean_style, n_sample, device):\n",
    "    image = generator(\n",
    "        torch.randn(n_sample, 512).to(device),\n",
    "        step=step,\n",
    "        alpha=1,\n",
    "        mean_style=mean_style,\n",
    "        style_weight=0.7,\n",
    "    )\n",
    "    \n",
    "    return image\n",
    "\n",
    "@torch.no_grad()\n",
    "def style_mixing(generator, step, mean_style, n_source, n_target, device):\n",
    "    source_code = torch.randn(n_source, 512).to(device)\n",
    "    target_code = torch.randn(n_target, 512).to(device)\n",
    "    \n",
    "    shape = 4 * 2 ** step\n",
    "    alpha = 1\n",
    "\n",
    "    images = [torch.ones(1, 3, shape, shape).to(device) * -1]\n",
    "\n",
    "    source_image = generator(\n",
    "        source_code, step=step, alpha=alpha, mean_style=mean_style, style_weight=0.7\n",
    "    )\n",
    "    target_image = generator(\n",
    "        target_code, step=step, alpha=alpha, mean_style=mean_style, style_weight=0.7\n",
    "    )\n",
    "\n",
    "    images.append(source_image)\n",
    "\n",
    "    for i in range(n_target):\n",
    "        image = generator(\n",
    "            # taget_code[i].size: (n_source, 512)\n",
    "            [target_code[i].unsqueeze(0).repeat(n_source, 1), source_code],\n",
    "            step=step,\n",
    "            alpha=alpha,\n",
    "            mean_style=mean_style,\n",
    "            style_weight=0.7,\n",
    "            mixing_range=(0, 1),\n",
    "        )\n",
    "        images.append(target_image[i].unsqueeze(0))\n",
    "        images.append(image)\n",
    "\n",
    "    images = torch.cat(images, 0)\n",
    "    \n",
    "    return images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--size', type=int, default=256, help='size of the image')\n",
    "parser.add_argument('--n_row', type=int, default=3, help='number of rows of sample matrix')\n",
    "parser.add_argument('--n_col', type=int, default=5, help='number of columns of sample matrix')\n",
    "parser.add_argument('--path', type=str, default='./stylegan-256px-new.model', help='path to checkpoint file')\n",
    "\n",
    "args = parser.parse_known_args()[0]\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "generator = StyledGenerator(512).to(device)\n",
    "generator.load_state_dict(torch.load(args.path)['g_running'])\n",
    "generator.eval()\n",
    "\n",
    "mean_style = get_mean_style(generator, device)\n",
    "\n",
    "step = int(math.log(args.size, 2)) - 2\n",
    "\n",
    "img = sample(generator, step, mean_style, args.n_row * args.n_col, device)\n",
    "utils.save_image(img, 'sample.png', nrow=args.n_col, normalize=True, range=(-1, 1))\n",
    "\n",
    "for j in range(20):\n",
    "    img = style_mixing(generator, step, mean_style, args.n_col, args.n_row, device)\n",
    "    utils.save_image(\n",
    "        img, f'sample_mixing_{j}.png', nrow=args.n_col + 1, normalize=True, range=(-1, 1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}